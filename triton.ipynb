{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "M=27\n",
    "N=24\n",
    "K=12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.7733e-01, -1.5123e-01, -1.2304e+00, -1.2133e+00, -1.7634e+00,\n",
       "           5.2637e-01, -1.0238e-01,  1.9525e+00,  6.2172e-02, -3.8843e-01,\n",
       "           1.1864e+00, -8.9849e-01],\n",
       "         [ 1.5296e+00,  6.9775e-01,  7.0850e-01,  1.4713e+00, -2.3854e-01,\n",
       "           8.3528e-01,  6.6553e-01,  5.4043e-01, -1.3814e+00,  1.6427e+00,\n",
       "           7.7671e-01,  8.5083e-01],\n",
       "         [ 1.8558e-01, -8.2642e-01,  1.5475e+00, -9.5888e-01,  3.4433e-01,\n",
       "           1.6822e+00,  1.4600e-01,  1.6899e+00,  1.5701e+00, -7.1533e-02,\n",
       "           8.8669e-01, -2.6985e-01],\n",
       "         [-8.9661e-01,  1.3808e+00, -9.9195e-01,  5.1477e-01,  2.0502e-02,\n",
       "          -8.3421e-01, -1.3154e+00,  8.7657e-01,  6.8434e-01,  1.0375e+00,\n",
       "          -3.6703e-01, -3.8922e-01],\n",
       "         [ 1.9106e+00,  3.4038e-01, -2.7778e-02,  1.7827e+00, -2.2811e-01,\n",
       "          -4.6403e-01,  7.6054e-01,  2.0389e+00, -2.5767e+00,  8.2621e-01,\n",
       "          -9.9550e-01,  1.6045e+00],\n",
       "         [-6.8568e-01,  2.3905e-01,  1.2484e+00, -3.0732e-01,  9.7490e-01,\n",
       "          -5.3547e-01, -6.4597e-01, -8.5214e-02,  7.1909e-03,  5.0982e-01,\n",
       "          -1.3187e+00,  1.6310e+00],\n",
       "         [ 8.5365e-01,  4.6926e-02,  1.9925e-01, -1.5079e+00, -1.1430e+00,\n",
       "           2.9984e-01, -2.7617e-01, -1.1851e+00, -1.7810e+00, -7.9865e-01,\n",
       "           8.7610e-01,  9.4042e-01],\n",
       "         [-1.0342e+00, -9.7169e-01, -2.4085e-01, -1.5284e+00, -1.0169e-01,\n",
       "           2.3015e+00, -7.3913e-01, -1.3510e+00,  6.5715e-01,  3.9462e-01,\n",
       "           1.9541e+00, -4.5738e-01],\n",
       "         [-1.1469e-01,  3.8777e-01,  1.6899e+00, -1.2450e+00, -1.7508e+00,\n",
       "          -6.7137e-01,  1.7618e+00,  8.2845e-01, -2.6099e-01,  4.4535e-01,\n",
       "           7.4306e-01, -6.1032e-02],\n",
       "         [-1.5872e-01,  4.7726e-01, -9.0262e-01,  5.8311e-01,  7.8707e-01,\n",
       "           1.2978e-01,  1.1591e+00, -4.3373e-01, -1.1097e+00, -8.6176e-01,\n",
       "          -1.6401e+00, -4.2440e-01],\n",
       "         [ 4.6887e-01,  1.8714e+00,  1.4872e+00,  1.5820e+00, -1.2207e-01,\n",
       "           2.7066e-01,  1.4420e+00, -3.1220e-01,  1.8340e-01, -3.4742e-01,\n",
       "          -1.5386e+00,  1.8821e+00],\n",
       "         [-1.9113e+00, -1.0422e+00,  4.1264e-01, -1.7927e-01, -7.0157e-02,\n",
       "           1.0067e+00, -1.0958e+00,  1.0019e+00, -1.5878e+00,  2.4126e+00,\n",
       "          -9.6581e-01, -1.0267e+00],\n",
       "         [ 1.0199e+00, -1.0788e+00, -1.0933e+00,  1.0278e+00,  1.6000e+00,\n",
       "          -1.6378e+00, -1.1628e+00,  9.5811e-01, -1.2440e+00,  1.9098e+00,\n",
       "          -4.2239e-01,  4.4752e-01],\n",
       "         [ 1.4072e-01,  8.0758e-01,  1.3188e+00, -6.8327e-01, -1.0194e+00,\n",
       "          -5.9497e-01, -8.8645e-01,  4.6451e-01, -4.6578e-01,  2.2933e-01,\n",
       "          -2.9250e-01, -1.3530e+00],\n",
       "         [ 2.0910e+00,  6.7863e-01, -9.0139e-01, -1.9664e-01,  1.2625e+00,\n",
       "           8.7073e-01, -1.0179e+00, -7.0798e-01,  6.5457e-01, -1.4267e+00,\n",
       "          -1.6788e-01,  6.6267e-01],\n",
       "         [ 1.4853e+00,  2.0600e-01, -1.4149e+00,  3.3151e-01, -1.8198e+00,\n",
       "           1.6482e-03, -8.1629e-01,  9.2778e-02,  9.8519e-01, -1.0947e+00,\n",
       "          -6.1741e-02,  1.2418e+00],\n",
       "         [ 9.0109e-01, -1.4459e-01, -1.5433e-01,  3.8066e-01, -1.5725e+00,\n",
       "           8.0783e-01, -6.4454e-01, -1.2707e+00, -6.8359e-02, -3.2532e-01,\n",
       "          -1.1507e+00, -7.4505e-01],\n",
       "         [ 1.5990e-01,  7.3849e-02,  1.0648e+00,  1.6330e+00,  1.0327e+00,\n",
       "          -4.9118e-02, -8.1585e-01, -1.2106e+00,  1.2867e-01, -1.9563e+00,\n",
       "           7.2390e-01, -6.8290e-01],\n",
       "         [ 2.1994e+00, -2.6053e-01,  4.8305e-02,  7.9438e-02,  7.9937e-01,\n",
       "           6.3533e-01,  1.0416e-01, -2.3320e-02,  8.1206e-01,  3.2654e-02,\n",
       "           4.5726e-01,  8.8771e-01],\n",
       "         [ 1.1450e+00, -1.8121e+00,  6.2668e-01, -5.8549e-01, -1.7998e+00,\n",
       "           4.2238e-01,  2.2002e-01, -1.3378e+00,  1.7643e-01,  2.9190e-01,\n",
       "          -8.7659e-01,  4.1500e-01],\n",
       "         [ 2.9163e-01, -1.0543e+00,  1.0953e+00, -7.7022e-01, -5.0259e-01,\n",
       "           4.3675e-01,  3.8114e-01,  3.9418e-01, -1.4609e-01, -7.7631e-03,\n",
       "           2.3467e-01, -5.8569e-01],\n",
       "         [ 3.2335e-01, -4.9265e-01, -7.3722e-03, -7.5335e-01, -5.0556e-01,\n",
       "          -9.1575e-01, -5.3630e-01,  9.6423e-01,  5.1690e-01,  6.6331e-01,\n",
       "           4.3010e-02,  6.5087e-01],\n",
       "         [ 8.6718e-02, -3.8852e-01, -4.1379e-01, -6.3364e-01,  1.7968e+00,\n",
       "           4.4122e-01, -3.6629e-01,  1.3917e+00, -5.1351e-01,  1.8902e+00,\n",
       "           5.1495e-01,  7.2040e-02],\n",
       "         [ 1.0559e+00,  1.2214e+00, -5.4078e-01,  1.7782e+00,  1.8462e+00,\n",
       "           1.9070e-01, -1.8678e+00, -1.5171e+00, -3.7041e-01,  1.0871e+00,\n",
       "           8.4022e-01,  1.8320e+00],\n",
       "         [-5.9508e-01, -7.6580e-01, -2.1527e+00, -3.8512e-01,  7.3953e-01,\n",
       "           8.1662e-01,  3.7468e-01, -4.9808e-01, -2.0567e-01,  8.1763e-01,\n",
       "           1.6179e+00,  4.2742e-01],\n",
       "         [ 1.3839e+00,  8.1948e-01, -1.2175e+00,  9.4964e-02, -8.0486e-01,\n",
       "          -5.3311e-01,  3.1233e-01, -1.4366e-01,  3.0131e-01, -8.6051e-01,\n",
       "           1.6323e+00, -5.0281e-01],\n",
       "         [-1.1030e+00,  8.1397e-01,  7.4266e-01,  1.1232e+00, -2.2416e-02,\n",
       "          -7.7026e-01,  1.1877e+00, -1.9136e+00, -8.5809e-01, -1.1459e+00,\n",
       "           1.4266e-01, -2.1449e+00]]),\n",
       " tensor([[-1.6463e+00,  5.9157e-01, -5.4039e-01, -3.2064e-02,  1.1838e+00,\n",
       "           8.4274e-02,  3.1783e-01, -1.1228e+00,  2.6351e-01,  9.6270e-01,\n",
       "           8.9051e-01, -3.2643e-01, -5.4344e-01,  1.1217e-01, -1.3893e-02,\n",
       "          -5.8446e-01,  4.7370e-01,  1.4099e+00, -5.6241e-01, -4.1862e-02,\n",
       "           1.7479e-01, -2.3189e+00, -2.4584e-01, -5.3797e-01],\n",
       "         [-1.1684e+00,  1.1021e+00, -4.0249e-01,  2.2185e-01, -9.1169e-01,\n",
       "           1.8641e-01,  5.9400e-01,  2.1504e+00,  3.5287e-01, -1.9342e+00,\n",
       "           1.5742e+00, -2.8086e-01, -2.4810e-01,  1.4324e-01, -4.2072e-02,\n",
       "           6.2583e-01, -9.2078e-02,  2.0844e+00, -1.3643e+00, -6.9331e-01,\n",
       "           9.5865e-01, -1.5430e+00,  1.6688e+00,  4.4857e-01],\n",
       "         [ 6.6211e-01, -8.3154e-01,  1.0035e+00, -1.1139e+00, -1.0567e+00,\n",
       "           5.9846e-02,  1.2400e+00, -3.8963e-01,  7.4810e-01,  6.6110e-01,\n",
       "          -4.6849e-01, -5.7153e-01,  4.1545e-02,  8.6874e-02,  2.7772e+00,\n",
       "           1.7920e-01, -7.2860e-01,  4.9429e-02,  1.4527e+00, -3.1695e-01,\n",
       "          -1.4931e+00,  1.3531e+00, -1.2368e+00, -2.4125e-01],\n",
       "         [-5.2283e-01, -9.8204e-01,  1.9078e-01, -1.7121e+00,  3.7202e-01,\n",
       "           1.5756e-01,  1.9436e+00, -6.9256e-01,  1.0304e+00,  2.2566e-01,\n",
       "           3.5139e-01,  3.5878e-02,  3.8151e-01,  5.3004e-01, -8.8618e-01,\n",
       "           1.0090e+00, -1.4227e+00, -9.6615e-01, -3.8519e-01,  2.1349e+00,\n",
       "           3.7217e-01, -1.5399e-01,  2.0151e+00,  8.1653e-02],\n",
       "         [ 4.8481e-01, -9.8963e-01, -3.5076e-01, -5.9965e-01, -6.4237e-01,\n",
       "           3.6888e-01, -1.2241e+00,  5.9322e-01, -5.9963e-01,  1.4251e+00,\n",
       "           4.5488e-01,  7.0159e-01,  8.6182e-02,  5.1973e-01,  6.7266e-01,\n",
       "           5.9437e-01,  6.1626e-01, -7.1661e-01,  6.4746e-01,  1.3418e+00,\n",
       "           1.5761e+00,  2.0517e+00, -2.4378e+00,  4.8420e-01],\n",
       "         [ 9.5113e-01, -5.7573e-01, -5.2214e-01,  1.2069e+00,  5.4283e-01,\n",
       "           5.6820e-01,  9.8313e-01, -5.4351e-01,  1.9903e-01,  1.0305e+00,\n",
       "           9.3370e-01, -7.4278e-02,  1.6433e-01, -6.4769e-01,  1.1185e-01,\n",
       "          -1.2299e-02,  6.9672e-01, -9.9193e-01,  1.2597e+00, -2.0056e+00,\n",
       "          -1.0600e+00, -2.8400e-01,  6.0639e-01, -1.9549e-01],\n",
       "         [ 1.3037e+00, -9.4506e-02,  4.5540e-01,  2.4696e-01, -5.5299e-01,\n",
       "           1.2758e+00, -3.3396e-01,  8.3074e-01, -8.9587e-02,  3.7439e-01,\n",
       "           2.1440e-01,  1.2477e+00,  2.0155e+00,  6.7892e-01, -1.1783e+00,\n",
       "          -7.8968e-01, -6.7696e-02, -1.5010e-01, -1.1077e+00,  1.1838e-01,\n",
       "           6.3728e-01,  7.8290e-02,  1.1501e+00,  2.7623e-01],\n",
       "         [ 1.6951e+00, -1.1922e+00,  3.1326e-01,  4.9279e-01, -6.5313e-01,\n",
       "           2.3884e-01, -1.3478e+00, -2.0812e+00,  4.5520e-01,  2.5300e-03,\n",
       "          -2.3487e-01, -9.8815e-01, -6.7636e-01, -1.5095e+00,  1.0952e+00,\n",
       "           9.1384e-01,  1.1309e+00, -1.8404e-01,  7.3046e-01,  1.0892e-01,\n",
       "          -8.4683e-01, -1.0290e+00,  1.2337e+00,  8.5937e-01],\n",
       "         [-1.1564e+00, -1.4811e+00,  5.9904e-01, -1.6205e-04,  1.8182e-01,\n",
       "           7.7111e-01, -2.1068e+00, -1.0367e+00,  1.5235e-02,  8.8081e-01,\n",
       "           8.6711e-01, -2.1320e-01, -8.0108e-03,  1.9963e+00, -5.0986e-01,\n",
       "          -1.0602e+00,  1.3600e+00,  2.4277e+00, -3.5790e-01,  2.5932e-01,\n",
       "           3.2600e-01, -1.4862e+00,  1.1963e+00,  7.4817e-01],\n",
       "         [ 4.3216e-01, -1.3706e+00,  2.3593e-02,  7.8485e-01, -1.1376e+00,\n",
       "           7.0971e-01,  6.3255e-01, -4.7476e-01,  8.7200e-01,  5.4890e-01,\n",
       "           1.3455e+00,  5.4596e-01, -7.0156e-02,  2.2840e-01, -8.1107e-01,\n",
       "          -2.6042e-01, -7.3363e-01, -1.1410e+00,  3.0997e+00, -1.4214e-02,\n",
       "           9.2808e-01,  6.9156e-01,  9.5266e-01,  5.9761e-02],\n",
       "         [-9.0871e-02,  1.5893e+00,  1.2040e+00,  4.1740e-01,  1.1910e+00,\n",
       "           7.6744e-01, -7.8728e-03,  3.0705e-01,  3.2914e-01,  1.2510e+00,\n",
       "          -5.4465e-01, -1.5443e-01,  3.3623e-01,  1.1502e+00, -2.6712e+00,\n",
       "          -7.9729e-01,  5.0717e-01,  1.4850e-01,  4.4842e-01,  7.4413e-01,\n",
       "           5.1250e-01,  4.1406e-01, -8.8166e-01, -1.7858e-01],\n",
       "         [-1.8935e+00, -5.5673e-01, -1.7036e+00,  3.4021e-01, -2.8415e-01,\n",
       "           1.5607e-01,  2.4083e-02,  1.0002e+00,  1.7274e-02,  1.1388e+00,\n",
       "           1.0533e+00, -1.1696e+00,  1.0873e+00, -9.7525e-01,  4.9171e-01,\n",
       "          -6.9851e-03,  1.4039e-01,  2.1234e-01, -1.5881e+00, -6.1680e-01,\n",
       "          -7.1608e-01, -1.6222e+00,  9.4657e-01, -2.3087e-03]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=torch.randn(M,K)\n",
    "B=torch.randn(K,N)\n",
    "A,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 24, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M,N,K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=torch.zeros(M,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_M = M//3\n",
    "block_N=N//3\n",
    "block_K=K//3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 8, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_M,block_N,block_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for start_M in range(0,M,block_M):\n",
    "    stop_M= start_M+block_M\n",
    "\n",
    "    \n",
    "    for start_N in range(0,N,block_N):\n",
    "        stop_N= start_N+block_N\n",
    "        \n",
    "        accum=torch.zeros(block_M,block_N)\n",
    "\n",
    "        for start_K in range(0,K,block_K):\n",
    "            stop_K=start_K+block_K\n",
    "            tile_A=A[start_M:stop_M,start_K:stop_K]\n",
    "            tile_B=B[start_K:stop_K,start_N:stop_N]\n",
    "            #print(\"tile A\",tile_A)\n",
    "            #print(\"tile B\",tile_B)\n",
    "            #print(tile_A.numel())\n",
    "\n",
    "            accum+=tile_A@tile_B\n",
    "            #print(\"accum \",accum)\n",
    "            \n",
    "\n",
    "        output[start_M:stop_M,start_N:stop_N]=accum\n",
    "\n",
    "torch.allclose(output, A@B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6842,  1.0767,  2.0093,  ..., -1.2793, -1.1738,  0.5916])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ptr=torch.randn(1050)\n",
    "x_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.arange(0,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,  ..., 1021, 1022, 1023])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  64,   65,   66,  ..., 1085, 1086, 1087])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset=64+torch.arange(0,1024)\n",
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm=1050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=offset<nm\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1050) must match the size of tensor b (1024) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[43mx_ptr\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43moffset\u001b[49m\n\u001b[0;32m      2\u001b[0m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1050) must match the size of tensor b (1024) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "x=x_ptr+offset\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0191, -1.1721, -0.4266,  0.8502,  0.1352],\n",
       "        [-0.3116, -0.8340, -0.8254,  0.1214,  0.9323],\n",
       "        [ 0.3426,  0.2967, -0.0836,  0.8714, -0.6098],\n",
       "        [ 0.2002,  0.1372,  1.3204,  1.6168,  0.4254]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(4,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max=x.max(dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8502, 0.9323, 0.8714, 1.6168])\n"
     ]
    }
   ],
   "source": [
    "print(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.3426, 0.2967, 1.3204, 1.6168, 0.9323]),\n",
      "indices=tensor([2, 2, 3, 3, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(x_max.shape)\n",
    "x_max_1=x.max(dim=0)\n",
    "print(x_max_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8311, -2.0223, -1.2767,  0.0000, -0.7150],\n",
      "        [-1.2439, -1.7663, -1.7577, -0.8110,  0.0000],\n",
      "        [-0.5289, -0.5747, -0.9551,  0.0000, -1.4812],\n",
      "        [-1.4166, -1.4797, -0.2965,  0.0000, -1.1914]])\n"
     ]
    }
   ],
   "source": [
    "r=x-x_max[:,None]\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8502],\n",
      "        [0.9323],\n",
      "        [0.8714],\n",
      "        [1.6168]])\n"
     ]
    }
   ],
   "source": [
    "print(x_max[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8502, 0.9323, 0.8714, 1.6168]])\n"
     ]
    }
   ],
   "source": [
    "print(x_max[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4356, 0.1324, 0.2789, 1.0000, 0.4892],\n",
      "        [0.2883, 0.1710, 0.1724, 0.4444, 1.0000],\n",
      "        [0.5893, 0.5629, 0.3848, 1.0000, 0.2274],\n",
      "        [0.2425, 0.2277, 0.7434, 1.0000, 0.3038]])\n"
     ]
    }
   ],
   "source": [
    "numerator=torch.exp(r)\n",
    "print(numerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3361, 2.0761, 2.7643, 2.5175])\n"
     ]
    }
   ],
   "source": [
    "denominator=numerator.sum(dim=1)\n",
    "print(denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerator shape torch.Size([4, 5])\n",
      "denomianator shape torch.Size([4])\n",
      "tensor([[0.1865, 0.0567, 0.1194, 0.4281, 0.2094],\n",
      "        [0.1388, 0.0823, 0.0831, 0.2141, 0.4817],\n",
      "        [0.2132, 0.2036, 0.1392, 0.3618, 0.0822],\n",
      "        [0.0963, 0.0905, 0.2953, 0.3972, 0.1207]])\n"
     ]
    }
   ],
   "source": [
    "print(\"numerator shape\",numerator.shape)\n",
    "print(\"denomianator shape\",denominator.shape)\n",
    "result=numerator/denominator[:,None]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "row_sum=result.sum(dim=1)\n",
    "print(row_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.6074e+04, 1.6381e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]) torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "y=torch.empty_like(x)\n",
    "print(y,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'the'}, {'cat'}, {'is'}, {'on'}, {'a'}, {'chair'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_order = [\"the\",\"cat\",\"is\",\"on\",\"a\",\"chair\"]\n",
    "sequence = [{print_order[i]} for i in range(len(print_order))]\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_size=3\n",
    "\n",
    "def sliding_window_attention(seq:list[set[str]],w:int):\n",
    "    seq_len=len(seq)\n",
    "    print(\"the length of sequence of type 'list[set[str]] is \",seq_len)\n",
    "    attention_scores: list[list[set]] = [[None for _ in range(seq_len)] for _ in range(seq_len)]\n",
    "    for i , q_i in enumerate(seq):\n",
    "        for j , q_j in enumerate(seq):\n",
    "\n",
    "            if j>i:\n",
    "                continue\n",
    "\n",
    "            if j-i>=w:\n",
    "                continue\n",
    "\n",
    "            attention=set()\n",
    "            attention.update(q_i)\n",
    "            attention.update(q_j)\n",
    "            attention_scores[i][j]=attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N,K = 27,27,8\n",
    "BLOCK_SIZE_M , BLOCK_SIZE_N , BLOCK_SIZE_K = 3,3,2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.3947e+00, -2.2940e-01,  2.1989e-01, -2.5202e-01,  8.1194e-01,\n",
       "          -2.6301e-01, -2.4291e-01, -2.8600e-01],\n",
       "         [ 1.4727e-01,  5.0780e-01,  8.0161e-01, -4.9933e-01,  1.5565e+00,\n",
       "          -3.2561e-01, -7.6039e-01, -2.5790e-01],\n",
       "         [ 3.3600e-01,  6.6345e-01, -2.4063e-01,  2.3834e-01,  6.5702e-01,\n",
       "          -1.1029e+00, -1.8345e+00,  1.4962e+00],\n",
       "         [ 2.9292e-01, -4.6175e-02,  7.2082e-01,  8.1139e-01, -5.6472e-01,\n",
       "          -1.0001e+00, -9.5001e-01, -3.6828e-01],\n",
       "         [ 9.7238e-01,  1.2278e+00,  2.2260e-01,  2.6480e-01, -6.8892e-01,\n",
       "          -7.0919e-01,  1.0436e+00,  6.1702e-01],\n",
       "         [-3.4161e-01, -9.1487e-01, -3.9451e-01,  6.8422e-01, -2.1132e+00,\n",
       "          -7.9409e-01,  1.3459e-01,  7.0443e-01],\n",
       "         [-2.6722e-01, -3.8839e-02,  1.4961e+00, -1.3221e+00, -2.9251e-01,\n",
       "           1.1699e+00,  1.6335e+00, -6.0037e-01],\n",
       "         [-1.5281e+00, -6.4492e-01,  3.5592e-01, -5.4961e-01, -2.4111e-01,\n",
       "           5.6049e-01,  5.6883e-01, -2.3266e-02],\n",
       "         [-1.2211e+00, -5.8801e-01,  1.9112e+00,  8.1942e-01,  1.7470e-01,\n",
       "          -4.2189e-01,  1.1595e-01,  6.4907e-03],\n",
       "         [-1.3119e+00,  1.8382e+00,  1.2715e+00,  9.3703e-01, -8.8702e-01,\n",
       "           8.6583e-01, -6.5250e-01,  8.5358e-01],\n",
       "         [ 1.8416e-01,  3.1760e-01, -2.6984e-01,  3.9316e-01,  1.2905e+00,\n",
       "          -1.7751e+00, -2.4340e-01, -3.7939e-02],\n",
       "         [-8.2902e-01, -4.0236e-01,  3.0206e-01, -5.6932e-02,  3.2613e-01,\n",
       "           9.8968e-01,  9.8583e-01, -1.8772e+00],\n",
       "         [ 8.2111e-01, -5.0287e-01,  9.4321e-01, -1.1127e+00, -2.0368e-01,\n",
       "           1.0970e+00,  4.1421e-01,  1.5774e+00],\n",
       "         [-9.1096e-01,  7.1524e-01,  1.2770e+00,  1.2507e+00,  3.3229e-01,\n",
       "           8.3404e-01,  1.6916e+00,  8.9415e-01],\n",
       "         [ 1.0097e+00,  5.4206e-01,  1.9120e-01,  1.9290e+00, -3.2028e-01,\n",
       "          -2.6421e-01,  2.5500e+00, -5.7506e-01],\n",
       "         [ 9.1656e-01,  1.7739e+00,  1.2069e+00,  8.2249e-02, -1.1376e-01,\n",
       "          -3.4889e-01,  9.1269e-01, -3.1982e-01],\n",
       "         [-4.7490e-01,  1.9755e-01,  8.6022e-01, -3.7699e-02,  1.6917e-01,\n",
       "           8.4739e-02, -1.4695e+00,  1.1771e+00],\n",
       "         [-2.2135e+00, -9.7594e-02, -6.8970e-01,  3.9502e-01,  8.8042e-01,\n",
       "          -3.7899e-01,  1.7784e+00, -7.3212e-02],\n",
       "         [-1.0278e+00, -6.8846e-01, -3.4792e-01, -5.2216e-01,  6.6603e-01,\n",
       "           6.9084e-01,  1.4339e+00,  1.2135e+00],\n",
       "         [-1.3208e-01, -1.5223e+00,  3.8160e-01, -1.5373e+00, -1.5419e+00,\n",
       "           3.8814e-01, -2.3783e-01,  7.0790e-01],\n",
       "         [-1.5015e-01, -6.2643e-01, -2.0655e+00,  2.0648e+00,  1.9731e-01,\n",
       "          -1.8625e+00, -4.3487e-01,  9.3228e-01],\n",
       "         [-1.8013e+00,  1.0345e+00, -3.3438e-01, -1.0885e+00,  4.7388e-01,\n",
       "           6.9500e-01,  8.4745e-01, -5.3310e-01],\n",
       "         [-2.1975e+00, -1.7497e-01, -1.9854e+00,  4.5538e-01, -2.4167e-01,\n",
       "           1.7404e+00,  1.0585e+00,  2.9126e-01],\n",
       "         [-3.4737e-01,  5.0278e-01, -4.6989e-01,  7.9933e-04, -3.5670e-02,\n",
       "           1.3882e-01,  1.5621e+00,  4.7735e-01],\n",
       "         [-3.7018e-02, -3.4019e-02,  3.5506e-01,  1.2762e-01,  3.0502e-01,\n",
       "           1.2274e-01, -4.8493e-01,  9.6612e-01],\n",
       "         [ 1.9135e+00, -1.4342e+00, -4.8021e-01,  6.5316e-01, -1.2475e+00,\n",
       "           5.3073e-01, -2.0257e-01, -1.0120e+00],\n",
       "         [ 8.1449e-01,  6.6189e-01, -7.2211e-01, -1.1401e-01,  5.5100e-01,\n",
       "           2.0644e+00,  1.5338e+00,  1.2198e+00]]),\n",
       " tensor([[ 1.3084e-01, -8.8817e-01,  1.0527e-01, -1.7054e-01, -4.7037e-01,\n",
       "           8.4346e-01, -1.8549e+00,  5.5951e-01, -3.6157e-01, -1.6239e+00,\n",
       "           1.0997e+00, -1.7000e+00,  9.4846e-01, -1.2109e+00,  5.2643e-02,\n",
       "           4.1022e-01, -3.3488e-01,  1.1281e+00, -1.1274e-01, -9.1985e-01,\n",
       "           1.5716e+00, -4.6929e-01, -1.2468e+00, -2.4744e-01,  3.0538e-01,\n",
       "           2.2869e-01, -8.5407e-01],\n",
       "         [-3.0216e-02, -2.3611e-01,  4.1976e-01,  6.1588e-02, -1.5691e-01,\n",
       "          -1.4004e+00,  9.3875e-01,  1.2861e+00, -5.4008e-02,  4.3317e-01,\n",
       "           1.7135e+00, -1.2724e+00,  1.4396e-01,  1.3729e+00,  9.5851e-01,\n",
       "           9.8838e-01,  5.8766e-01, -9.9788e-01,  1.4512e-01,  1.6487e-01,\n",
       "          -7.7059e-01, -1.6561e-01,  3.4471e-01,  1.2293e+00,  1.4314e+00,\n",
       "           6.4511e-01,  7.4288e-01],\n",
       "         [ 2.0479e+00,  3.3275e-01,  1.7959e+00, -1.0653e-01, -7.9504e-01,\n",
       "           2.0584e+00, -4.4865e-01,  1.3554e+00,  1.0702e+00,  7.9001e-01,\n",
       "          -1.4347e+00, -8.4922e-01, -4.1172e-01, -1.0131e+00, -3.3177e-01,\n",
       "          -7.9386e-01,  2.8164e+00,  2.5171e-03,  4.2444e-01, -1.0877e+00,\n",
       "          -8.0735e-01,  4.0594e-02, -2.3307e+00, -1.1168e-01,  1.7191e+00,\n",
       "           3.8107e-01,  1.7795e+00],\n",
       "         [-2.1125e-01, -1.0471e+00, -6.5180e-01,  6.5971e-01, -5.9959e-01,\n",
       "           8.8976e-01,  8.4364e-01, -2.0517e-01,  3.1478e-01,  5.1033e-01,\n",
       "          -5.8517e-01,  2.0909e+00, -3.2858e-01, -1.2926e+00, -9.4028e-02,\n",
       "           7.9272e-02, -1.2170e-01,  1.1386e+00,  1.2339e+00, -4.2813e-01,\n",
       "          -7.1415e-01, -1.5234e+00, -1.7162e-01, -1.6373e-02, -2.7957e+00,\n",
       "          -1.7451e+00, -3.0093e-01],\n",
       "         [-2.1728e+00, -1.9678e+00,  7.2814e-01, -5.5278e-01,  1.1588e+00,\n",
       "           4.3275e-01,  5.7623e-01, -1.4271e+00, -6.9138e-01,  6.2880e-01,\n",
       "          -8.9814e-01,  1.0118e+00,  9.7905e-02,  1.7034e+00, -1.5177e+00,\n",
       "           7.4627e-01, -1.2024e+00, -6.5447e-01,  7.4489e-01, -1.0758e+00,\n",
       "          -4.6648e-01, -3.1437e+00,  7.3720e-01,  6.2348e-01, -7.6026e-01,\n",
       "          -7.6731e-02, -1.0831e+00],\n",
       "         [ 3.9461e-01, -5.3932e-01,  1.4549e+00,  1.5086e+00,  8.5331e-01,\n",
       "           1.6065e+00, -5.6722e-01,  1.2949e+00,  1.0921e+00,  8.7551e-01,\n",
       "          -2.7090e-01, -1.7731e+00,  1.3097e-01, -8.6553e-01,  3.9281e-01,\n",
       "          -5.9610e-01, -1.1920e-01,  4.8652e-01,  7.9722e-01, -1.0979e+00,\n",
       "           1.6600e+00, -1.1051e-01,  2.4655e+00,  5.1047e-01, -4.0374e-01,\n",
       "           1.0527e-01,  2.5940e+00],\n",
       "         [ 2.6506e+00,  1.5526e-01, -1.3740e-01, -9.9069e-01, -1.2321e+00,\n",
       "           1.4040e-01, -2.0747e+00,  7.1697e-01, -4.2932e-01, -8.4891e-01,\n",
       "          -1.2706e+00, -9.6487e-01, -4.1053e-01,  1.1509e+00, -5.7221e-01,\n",
       "           6.8304e-02,  5.2072e-01,  4.1613e-01,  9.5028e-01,  1.9705e+00,\n",
       "          -4.2346e-01,  4.5892e-01, -7.9396e-01, -3.3388e-01, -6.2583e-01,\n",
       "          -7.4012e-02, -9.1872e-01],\n",
       "         [ 1.8701e+00,  9.0702e-01,  1.5850e+00, -5.1629e-01,  8.8445e-02,\n",
       "          -1.1184e+00, -1.0750e+00,  3.8374e-01, -3.8902e-01, -3.1814e+00,\n",
       "          -8.4050e-01, -3.3554e-01,  7.2166e-01, -4.4249e-01, -5.7937e-01,\n",
       "          -7.7698e-01, -1.4744e+00, -3.8088e-01,  5.1758e-01, -2.1337e+00,\n",
       "          -9.2152e-01, -8.5472e-01, -1.1186e+00, -6.0201e-01,  4.4951e-01,\n",
       "          -8.0465e-01, -2.3293e+00]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=torch.randn(M,K)\n",
    "B=torch.randn(K,N)\n",
    "A,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (2) must match the existing size (3) at non-singleton dimension 1.  Target sizes: [2, 2].  Tensor sizes: [3, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m   b \u001b[38;5;241m=\u001b[39m B[k : k\u001b[38;5;241m+\u001b[39mBLOCK_SIZE_K, n : n\u001b[38;5;241m+\u001b[39mBLOCK_SIZE_N]\n\u001b[0;32m      9\u001b[0m   acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (a \u001b[38;5;241m@\u001b[39m b)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mC\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mBLOCK_SIZE_M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mBLOCK_SIZE_N\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m acc\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (2) must match the existing size (3) at non-singleton dimension 1.  Target sizes: [2, 2].  Tensor sizes: [3, 3]"
     ]
    }
   ],
   "source": [
    "for m in range(0, M, BLOCK_SIZE_M):\n",
    "  # Do in parallel\n",
    "  for n in range(0, N, BLOCK_SIZE_N):\n",
    "    acc = torch.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=torch.float32)\n",
    "    C=torch.zeros(BLOCKSIZE_M,BLOCKSIZE_N)\n",
    "    for k in range(0, K, BLOCK_SIZE_K):\n",
    "      a = A[m : m+BLOCK_SIZE_M, k : k+BLOCK_SIZE_K]\n",
    "      b = B[k : k+BLOCK_SIZE_K, n : n+BLOCK_SIZE_N]\n",
    "      acc += (a @ b)\n",
    "    C[m : m+BLOCK_SIZE_M, n : n+BLOCK_SIZE_N] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
